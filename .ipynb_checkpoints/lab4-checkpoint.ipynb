{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "383075d4f797ffc1",
   "metadata": {},
   "source": [
    "# Lab 4-1: Data preprocessing. Building a regression model.\n",
    "\n",
    "In this lab will write a simple regression model to predict the solubility of chemical molecules. We will use the `RDKit` library to calculate molecular descriptors from SMILES strings, and the `scikit-learn` library to build a regression model.\n",
    "\n",
    "We will learn how to get different molecular decriptors from SMILES strings with the use od `RDKit` library. Then we will preprocess data, implement a featurizer for automatic input data preparation, and wrap the whole process in a simple, user-friendly web app using `Streamlit`.\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49a509e53faea6b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Solubility</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N,N,N-trimethyloctadecan-1-aminium bromide</td>\n",
       "      <td>[Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C</td>\n",
       "      <td>-3.616127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benzo[cd]indol-2(1H)-one</td>\n",
       "      <td>O=C1Nc2cccc3cccc1c23</td>\n",
       "      <td>-3.254767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4-chlorobenzaldehyde</td>\n",
       "      <td>Clc1ccc(C=O)cc1</td>\n",
       "      <td>-2.177078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...</td>\n",
       "      <td>[Zn++].CC(c1ccccc1)c2cc(C(C)c3ccccc3)c(O)c(c2)...</td>\n",
       "      <td>-3.924409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...</td>\n",
       "      <td>C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...</td>\n",
       "      <td>-4.662065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0         N,N,N-trimethyloctadecan-1-aminium bromide   \n",
       "1                           Benzo[cd]indol-2(1H)-one   \n",
       "2                               4-chlorobenzaldehyde   \n",
       "3  zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...   \n",
       "4  4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...   \n",
       "\n",
       "                                              SMILES  Solubility  \n",
       "0                [Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C   -3.616127  \n",
       "1                               O=C1Nc2cccc3cccc1c23   -3.254767  \n",
       "2                                    Clc1ccc(C=O)cc1   -2.177078  \n",
       "3  [Zn++].CC(c1ccccc1)c2cc(C(C)c3ccccc3)c(O)c(c2)...   -3.924409  \n",
       "4  C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...   -4.662065  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('data/aqsol.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ab12a34250cf4e1",
   "metadata": {},
   "source": [
    "## Calculating molecular descriptors with RDKit\n",
    "\n",
    "**RDKit is a collection of cheminformatics tools, widely used to analyze and process chemical data.** We will use some of its functionalities to calculate molecular descriptors for the molecules in our dataset, and use the descriptors as input features for a regression model that will learn to predict the solubility of the molecules from SMILES strings. \n",
    "\n",
    "For this task will use only one submodule of RDKit, `rdkit.Chem.rdMolDescriptors`, which contains functions for calculating the molecular descriptors we are interested in. Feel free to explore RDKit yourself by reading [rdMolDescriptors documentation](https://www.rdkit.org/docs/source/rdkit.Chem.rdMolDescriptors.html) and [RDKit documentation](https://www.rdkit.org/docs/index.html).\n",
    "\n",
    "The most important RDKit class is `Mol` which represents a molecule with its atoms, bonds, spatial conformation, etc. Most RDKit functions, including those for calculating molecular descriptors, take a `Mol` object as input. If you have a SMILES string, you can create a `Mol` object using the `Chem.MolFromSmiles` function, as shown below:\n",
    "\n",
    "```python\n",
    "from rdkit import Chem\n",
    "\n",
    "smiles = 'C1C(=O)NC2=C(C=C(C=C2)[N+](=O)[O-])C(=N1)C3=CC=CC=C3'\n",
    "mol = Chem.MolFromSmiles(smiles)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d60f4277dd88387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>SMILES</th>\n",
       "      <th>Solubility</th>\n",
       "      <th>mol</th>\n",
       "      <th>mol_wt</th>\n",
       "      <th>logp</th>\n",
       "      <th>num_heavy_atoms</th>\n",
       "      <th>num_HBD</th>\n",
       "      <th>num_HBA</th>\n",
       "      <th>aromatic_rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N,N,N-trimethyloctadecan-1-aminium bromide</td>\n",
       "      <td>[Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C</td>\n",
       "      <td>-3.616127</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000225D0B...</td>\n",
       "      <td>391.281363</td>\n",
       "      <td>3.9581</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Benzo[cd]indol-2(1H)-one</td>\n",
       "      <td>O=C1Nc2cccc3cccc1c23</td>\n",
       "      <td>-3.254767</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000225D0B...</td>\n",
       "      <td>169.052764</td>\n",
       "      <td>2.4055</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4-chlorobenzaldehyde</td>\n",
       "      <td>Clc1ccc(C=O)cc1</td>\n",
       "      <td>-2.177078</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000225D0B...</td>\n",
       "      <td>140.002892</td>\n",
       "      <td>2.1525</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...</td>\n",
       "      <td>[Zn++].CC(c1ccccc1)c2cc(C(C)c3ccccc3)c(O)c(c2)...</td>\n",
       "      <td>-3.924409</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000225D0B...</td>\n",
       "      <td>754.227281</td>\n",
       "      <td>8.1161</td>\n",
       "      <td>53</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...</td>\n",
       "      <td>C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...</td>\n",
       "      <td>-4.662065</td>\n",
       "      <td>&lt;rdkit.Chem.rdchem.Mol object at 0x00000225D0B...</td>\n",
       "      <td>422.220557</td>\n",
       "      <td>2.4854</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Name  \\\n",
       "0         N,N,N-trimethyloctadecan-1-aminium bromide   \n",
       "1                           Benzo[cd]indol-2(1H)-one   \n",
       "2                               4-chlorobenzaldehyde   \n",
       "3  zinc bis[2-hydroxy-3,5-bis(1-phenylethyl)benzo...   \n",
       "4  4-({4-[bis(oxiran-2-ylmethyl)amino]phenyl}meth...   \n",
       "\n",
       "                                              SMILES  Solubility  \\\n",
       "0                [Br-].CCCCCCCCCCCCCCCCCC[N+](C)(C)C   -3.616127   \n",
       "1                               O=C1Nc2cccc3cccc1c23   -3.254767   \n",
       "2                                    Clc1ccc(C=O)cc1   -2.177078   \n",
       "3  [Zn++].CC(c1ccccc1)c2cc(C(C)c3ccccc3)c(O)c(c2)...   -3.924409   \n",
       "4  C1OC1CN(CC2CO2)c3ccc(Cc4ccc(cc4)N(CC5CO5)CC6CO...   -4.662065   \n",
       "\n",
       "                                                 mol      mol_wt    logp  \\\n",
       "0  <rdkit.Chem.rdchem.Mol object at 0x00000225D0B...  391.281363  3.9581   \n",
       "1  <rdkit.Chem.rdchem.Mol object at 0x00000225D0B...  169.052764  2.4055   \n",
       "2  <rdkit.Chem.rdchem.Mol object at 0x00000225D0B...  140.002892  2.1525   \n",
       "3  <rdkit.Chem.rdchem.Mol object at 0x00000225D0B...  754.227281  8.1161   \n",
       "4  <rdkit.Chem.rdchem.Mol object at 0x00000225D0B...  422.220557  2.4854   \n",
       "\n",
       "   num_heavy_atoms  num_HBD  num_HBA  aromatic_rings  \n",
       "0               23        0        0               0  \n",
       "1               13        1        1               2  \n",
       "2                9        0        1               1  \n",
       "3               53        2        6               6  \n",
       "4               31        0        6               2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from rdkit import Chem\n",
    "from rdkit.Chem import rdMolDescriptors\n",
    "from rdkit.Chem import Crippen\n",
    "from rdkit import RDLogger  \n",
    "RDLogger.DisableLog('rdApp.*') # Disabling rdkit warnings\n",
    "\n",
    "# First, we will create a mol object for each molecule in the dataset, and store it in a new column\n",
    "df['mol'] = df['SMILES'].apply(Chem.MolFromSmiles)\n",
    "\n",
    "# Now we can calculate the molecular descriptors\n",
    "df['mol_wt'] = df['mol'].apply(rdMolDescriptors.CalcExactMolWt)             # Molecular weight\n",
    "df['logp'] = df['mol'].apply(Crippen.MolLogP)                               # LogP (lipophilicity)\n",
    "df['num_heavy_atoms'] = df['mol'].apply(rdMolDescriptors.CalcNumHeavyAtoms) # Number of heavy atoms\n",
    "df['num_HBD'] = df['mol'].apply(rdMolDescriptors.CalcNumHBD)                # Number of hydrogen bond donors\n",
    "df['num_HBA'] = df['mol'].apply(rdMolDescriptors.CalcNumHBA)                # Number of hydrogen bond acceptors\n",
    "df['aromatic_rings'] = df['mol'].apply(rdMolDescriptors.CalcNumAromaticRings) # Number of aromatic rings\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b96d1421ed6e46",
   "metadata": {},
   "source": [
    "## Exercise 1: Extract features and split the dataset (1 point)\n",
    "\n",
    "Now that we have the molecular descriptors, we can use them as input features for a regression model. As we did in the previous lab, we will extract the **input features** $X$ and the target variable $y$, and split the dataset into training and test sets.\n",
    "\n",
    "Let's use the newly calculated molecular descriptors as input features, and the solubility as the target variable.\n",
    "\n",
    "1. Extract the input features and the target variable from the dataset\n",
    "2. Split the dataset into training and test sets, with a test size of 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf2da0c4db1756bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only the relevant columns of the dataframe (features and target)\n",
    "\n",
    "X = df[['mol_wt', 'logp','num_heavy_atoms','num_HBD','num_HBA','aromatic_rings']]    # select only the 'x1' and 'x2' columns as features\n",
    "y = df['Solubility'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdc72dac8094e7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c6e695e991ef6e8",
   "metadata": {},
   "source": [
    "## Exercise 2: Build a regression model (2 points)\n",
    "\n",
    "You already know the `scikit-learn` library, as we used it to build some classifier models in the previous labs. Now, we will use it to build a regression model. Linear regression is the simplest regression model, and it is a good starting point for regression problems. It is implemented in scikit-learn as `LinearRegression`. You should also try a more complex model, such as `SVR` (Support Vector Regression) and compare the results.\n",
    "\n",
    "1. Train a `LinearRegression` model on the training set. Report $RMSE$ (Root Mean Squared Error) and $R^2$ score on the train and test sets.\n",
    "2. Train an `SVR` model on the training set. Report $RMSE$ and $R^2$ score on the train and test sets. **Use the default hyperparameters for now.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddd091b6b7bf3023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression()\n",
      "Train RMSE 1.7544374594055134\n",
      "Test RMSE 1.6869726101410703\n",
      "SVR\n",
      "Train RMSE 1.7271979222101232\n",
      "Test RMSE 1.7360879177184636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Ellipsis"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train,y_train)\n",
    "lr_train_pred=lr.predict(X_train)\n",
    "lr_test_pred=lr.predict(X_test)\n",
    "\n",
    "lr_train_rmse= mean_squared_error(y_train, lr_train_pred, squared=False)\n",
    "lr_test_rmse= mean_squared_error(y_test, lr_test_pred, squared=False)\n",
    "print(lr)\n",
    "print('Train RMSE', lr_train_rmse)\n",
    "print('Test RMSE', lr_test_rmse)\n",
    "\n",
    "svr = SVR()\n",
    "svr.fit(X_train,y_train)\n",
    "svr_train_pred=svr.predict(X_train)\n",
    "svr_test_pred=svr.predict(X_test)\n",
    "\n",
    "svr_train_rmse= mean_squared_error(y_train, svr_train_pred, squared=False)\n",
    "svr_test_rmse= mean_squared_error(y_test, svr_test_pred, squared=False)\n",
    "print('SVR')\n",
    "print('Train RMSE', svr_train_rmse)\n",
    "print('Test RMSE', svr_test_rmse)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba17e8dbfa3cfdc",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "**Standardization** of datasets is a common requirement for many machine learning estimators implemented in scikit-learn. If some features of our data have very different scales (for example, one feature is in the range $[0, 1]$ and another can potentially be any positive number), **some models** might consider the feature with larger numerical values to be more important. This can be a problem, as we want our model to be able to learn from all features equally.\n",
    "\n",
    "Standardization transform our data in such a way that its distribution will have a mean value $\\mu = 0$ and standard deviation $\\sigma = 1$. We can achieve this by using the `StandardScaler` from the `sklearn` library.\n",
    "\n",
    "Another common preprocessing step is **normalization**. In this case, the data is scaled to a fixed range, usually $[0, 1]$. The motivation to use this scaling method includes preserving zeros in sparse data. For example, when making predictions about the expected outcome of an anticancer therapy, the value of $0$ observed tumors in a patient is probably much more informative for the predictive model than any other number of observed tumors alone. We can scale data to a certain range by using the `MinMaxScaler` from the `sklearn` library.\n",
    "\n",
    "You can read more about those two feature scaling methods in the [Scikit-learn preprocessing docs](https://scikit-learn.org/stable/modules/preprocessing.html).\n",
    "\n",
    "<center>\n",
    "    <img src=\"imgs/logp-std.png\" width=\"500\">\n",
    "</center>\n",
    "<br>\n",
    "\n",
    "**Remember that the scaler should be fitted only on the training set, and then used to transform both the training and test sets.** If we first transform the entire dataset and then split it into training and test sets, we are leaking the information about **test set data distribution** to the model, which would lead to overly optimistic results.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "...\n",
    "```\n",
    "\n",
    "\n",
    "## Exercise 3: Preprocess the input features (2 points)\n",
    "\n",
    "1. Standardize the input features using the `StandardScaler` from `sklearn`. **Fit the scaler on the training set and then transform both the training and test sets**.\n",
    "2. Train both linear regression and SVR models on the standardized training set. Report $RMSE$ and $R^2$ score on the train and test sets. How do the results compare to the previous models? Which model benefits from standardization?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b6b760550de9e5e7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'r2_score' from 'sklearn' (C:\\Users\\HP\\anaconda3\\envs\\pum\\lib\\site-packages\\sklearn\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m r2_score\n\u001b[0;32m      3\u001b[0m scaler\u001b[38;5;241m=\u001b[39mStandardScaler()\n\u001b[0;32m      5\u001b[0m X_train\u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(X_train) \u001b[38;5;66;03m# transform od razu po tym je odskaluje\u001b[39;00m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'r2_score' from 'sklearn' (C:\\Users\\HP\\anaconda3\\envs\\pum\\lib\\site-packages\\sklearn\\__init__.py)"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import r2_score\n",
    "scaler=StandardScaler()\n",
    "\n",
    "X_train= scaler.fit_transform(X_train) # transform od razu po tym je odskaluje\n",
    "X_test = scaler.transform(X_test) #\n",
    "\n",
    "lr.fit\n",
    "test_pred= lr.predict(X_test)\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7788a1513ee0f54",
   "metadata": {},
   "source": [
    "## Exercise 4: Featurizer class (2 points)\n",
    "\n",
    "All the data manipulations, including the generation of features (molecular descriptors) and scaling we did completely by hand. Imagine that we have a new dataset with molecules for which we want to predict the solubility. We would have to repeat all the steps we did above, which is not at all user-friendly.\n",
    "\n",
    "Let's encapsulate all the steps in a single class called `Featurizer`. \n",
    "\n",
    "**Featurizer is a piece of code which takes care of extracting the features and preparing them** in such a way that they can be used as an input for a ML model. In this fashion, our featurizer will be able to take a list of SMILES strings and return a dataframe with the molecular descriptors, ready to be used in any regression model.\n",
    "\n",
    "The `Featurizer` class should have the following methods:\n",
    "\n",
    "1. `__init__(self, smiles)`\n",
    "\n",
    "    The constructor method should take an array of **training set** SMILES strings as input and calculate the molecular descriptors for each molecule (in a `pandas.DataFrame`, as we did earlier). **It should also fit a scaler to the descriptors.** The descriptors should be stored in a dataframe, and the scaler should be stored as an attribute of the class.\n",
    "      \n",
    "\n",
    "2. `featurize(self, smiles)`\n",
    "    \n",
    "   This method should take an array of SMILES strings as input and return a dataframe with the molecular descriptors calculated with RDKit. **The descriptors should be standardized using the scaler which was fitted to the training set in the `__init__` method**.\n",
    "\n",
    "3. **You are more than welcome to implement other methods** if you think it will make your code cleaner or more efficient. Maybe we could have a separate method for the calculation of molecular descriptors, or for the scaling of the features?\n",
    "\n",
    "\n",
    "### Here is an example of how our `Featurizer` class should be used\n",
    "```python\n",
    "featurizer = Featurizer(X_train['SMILES'])  # Create an instance of the Featurizer class, passing the training set SMILES strings\n",
    "\n",
    "# Say we want to predict the solubility of the following molecules\n",
    "some_SMILES = ['CC(=O)Oc1ccccc1C(=O)O',     \n",
    "               'C1=CC(=C(C=C1[C@H](CN)O)O)O',\n",
    "               'C1=NC2=C(C(=N1)N)N=CN2C3C(C(C(O3)CO)O)O']\n",
    "\n",
    "# Extract the features\n",
    "X = featurizer.featurize(some_SMILES)\n",
    "\n",
    "...\n",
    "\n",
    "y_pred = model.predict(X)   # Get predictions\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fdba06d2dc54ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Featurizer: # w kazdej klasie metoda _init_ to to co bedzie sie dzialo przy tworzeniu obiektu tej klasy\n",
    "    def __init__(self, train_df):\n",
    "        self.scaler = StandardScaler() # self daje to, ze teraz scaler bedzie cecha klasy featurizer\n",
    "        features_train= self.generate_desciptors(train_df)\n",
    "        self.scaler.fit(features_train) #(self.generate_descriptors(train_df)) # dajemy mu jaki byl rozklad normalny dla danych\n",
    "        \n",
    "    def featurize(self, smiles): # wypluwa przeskalowane juz cechy dla kazdego zwiazku\n",
    "        df = pd.DataFrame(smiles, columns=['SMILES'])\n",
    "        descriptors=self.generate.descriptors(smiles)\n",
    "        #self.scaler.transform(descriptors)\n",
    "        return self.scaler.transform(descriptors)\n",
    "        \n",
    "    def generate_descriptors(self,df):\n",
    "        df['mol'] = df['SMILES'].apply(Chem.MolFromSmiles)\n",
    "        # Now we can calculate the molecular descriptors\n",
    "        df['mol_wt'] = df['mol'].apply(rdMolDescriptors.CalcExactMolWt)             # Molecular weight\n",
    "        df['logp'] = df['mol'].apply(Crippen.MolLogP)                               # LogP (lipophilicity)\n",
    "        df['num_heavy_atoms'] = df['mol'].apply(rdMolDescriptors.CalcNumHeavyAtoms) # Number of heavy atoms\n",
    "        df['num_HBD'] = df['mol'].apply(rdMolDescriptors.CalcNumHBD)                # Number of hydrogen bond donors\n",
    "        df['num_HBA'] = df['mol'].apply(rdMolDescriptors.CalcNumHBA)                # Number of hydrogen bond acceptors\n",
    "        df['aromatic_rings'] = df['mol'].apply(rdMolDescriptors.CalcNumAromaticRings) # Number of aromatic rings\n",
    "        return df[['mol_wt', 'logp','num_heavy_atoms','num_HBD','num_HBA','aromatic_rings']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8054c47c9dab6f61",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Featurizer' object has no attribute 'generate_desciptors'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Test your featurizer\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m featurizer \u001b[38;5;241m=\u001b[39m \u001b[43mFeaturizer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Pass the training set SMILES strings to the constructor\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      7\u001b[0m tryptamines \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata/tryptamines.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)   \u001b[38;5;66;03m# Load a new dataset\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[27], line 4\u001b[0m, in \u001b[0;36mFeaturizer.__init__\u001b[1;34m(self, train_df)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, train_df):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m StandardScaler() \u001b[38;5;66;03m# self daje to, ze teraz scaler bedzie cecha klasy featurizer\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     features_train\u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_desciptors\u001b[49m(train_df)\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mfit(features_train)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Featurizer' object has no attribute 'generate_desciptors'"
     ]
    }
   ],
   "source": [
    "# Test your featurizer\n",
    "\n",
    "featurizer = Featurizer(...) # Pass the training set SMILES strings to the constructor\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "tryptamines = pd.read_csv('data/tryptamines.csv')   # Load a new dataset\n",
    "tryptamines.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb8e9765cba0f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = featurizer.featurize(tryptamines['SMILES'])   # Extract features for the new dataset\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c47cf735cf5cb1d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Predict the solubility of the new molecules\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43msvr\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X)  \u001b[38;5;66;03m# Use the linear regression model to predict the solubility\u001b[39;00m\n\u001b[0;32m      5\u001b[0m tryptamines[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSolubility\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred  \u001b[38;5;66;03m# Add the predictions to the dataframe\u001b[39;00m\n\u001b[0;32m      6\u001b[0m tryptamines\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'svr' is not defined"
     ]
    }
   ],
   "source": [
    "# Predict the solubility of the new molecules\n",
    "\n",
    "y_pred = svr.predict(X)  # Use the linear regression model to predict the solubility\n",
    "\n",
    "tryptamines['Solubility'] = y_pred  # Add the predictions to the dataframe\n",
    "tryptamines.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f535942fbf64684",
   "metadata": {},
   "source": [
    "## Cross-validation and grid search\n",
    "\n",
    "Now that we have a working regression model, we can try to improve its performance by tuning the hyperparameters. Last time we tuned the hyperparameters by hand, but as you may guess, that is not the most efficient way to do it. What we can (and will) do is employ a **search algorithm** to find the best hyperparameters automatically. This piece of code will try different hyperparameters and return the best combination.\n",
    "\n",
    "Last time we introduced the concept of a **validation set**, which is a subset of the training set used to evaluate the model's performance during hyperparameter tuning. To tune the hyperparameters of a classifier model we cut out a part of the training set and used the accuracy on this validation set as a metric to evaluate the model's performance.\n",
    "\n",
    "In practice, when tuning hyperparameters of a machine learning model, we do not usually create a single validation set. Instead, we employ a srategy called **cross-validation**. In $k$-fold cross-validation, the process of training and evaluating the model is repeated $k$ times, with each repetition using a different validation set. Thanks to this strategy, each data point present in the original training set will have the chance to be included in a validation sets. The metrics reported from $k$ folds are then averaged to get a more reliable estimate of the model's performance.\n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/cross-validation.png\" width=\"800\">\n",
    "</center>\n",
    "\n",
    "Luckily, we do not have to implement this algorithm ourselves, as scikit-learn provides a `GridSearchCV` class that can help us with this task. It performs an exhaustive search over a specified parameter grid and evaluates the model's performance using $k$-fold cross-validation. By default, `GridSearchCV` uses a 5-fold cross-validation, which is a common choice for $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90aeecb460602ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "svr = SVR()\n",
    "\n",
    "# We will define a grid of hyperparameters as a dictionary. The keys are the hyperparameter names, and the values are lists of possible values to try.\n",
    "\n",
    "param_grid = {\n",
    "    'C': [1, 5, 10, 20, 50, 100],\n",
    "    'epsilon': [0.001, 0.01, 0.1, 0.5, 1]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    svr, # the model\n",
    "    param_grid, # the grid of hyperparameters\n",
    "    verbose=2 # print the progress\n",
    ")\n",
    "\n",
    "svr = grid_search.fit(X_train, y_train) # GridSearchCV.fit() returns the best model, and we can save it to a new variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc8f7c1b8fb2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Report the best hyperparameters and RMSE on the testing set\n",
    "\n",
    "print('Best hyperparameters:', svr.get_params())\n",
    "\n",
    "y_pred = svr.predict(X_test)\n",
    "\n",
    "print('-'*50)\n",
    "print('Testing set rmse:', mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f84dd5deebbd0d9",
   "metadata": {},
   "source": [
    "### *Randomized search\n",
    "\n",
    "`RandomizedSearchCV` is an alternative to `GridSearchCV`. Instead of trying all possible combinations of fixed hyperparameters, it samples a fixed number of hyperparameter settings from specified probability distributions. Although you may be hesitant to use it, as it is not an exhaustive search, it is often more efficient than grid search. Randomized search is especially useful when we have many hyperparameters to tune, and we are not sure which ones are the most important. Take a look at the figure below and try to understand why this is the case.\n",
    "\n",
    "<center>\n",
    "<img src=\"imgs/grid-vs-random.png\", width=\"600\">\n",
    "</center>\n",
    "\n",
    "Randomized search is implemented in the same way as grid search, but with a different class. It also requires a dictionary of hyperparameters, but instead of specifying a list of values to try, we specify a **probability distribution**. See the example below:\n",
    "\n",
    "```python\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import uniform\n",
    "\n",
    "param_distributions = {\n",
    "    'some_discete_hyperparameter': np.arange(1, 10), # uniform dicrete distribution from 1 to 10\n",
    "    'some_continuous_hyperparameter': uniform(0, 1), # uniform continuous distribution from 0 to 1\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    model,\n",
    "    param_distributions,\n",
    "    n_iter=100 # number of random samples to try\n",
    ")\n",
    "...\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc86bf1e4ca2c1d0",
   "metadata": {},
   "source": [
    "## Saving and loading Python objects\n",
    "\n",
    "Both the featurizer and the trained regression model can be saved to disk as Python objects using the `pickle` module. This way, we can load them later in another script without the need to retrain the model or recalculate the molecular descriptors.\n",
    "\n",
    "```python\n",
    "import pickle\n",
    "\n",
    "# Save the model\n",
    "\n",
    "with open('path/to/model.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)\n",
    "\n",
    "# Load the model\n",
    "\n",
    "with open('path/to/model.pkl', 'rb') as f:\n",
    "    model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb403d9e17203e7",
   "metadata": {},
   "source": [
    "---\n",
    "# Lab 4-2: Coding a simple app in Streamlit.\n",
    "\n",
    "Streamlit is a Python library that allows you to create very nice-looking and user-friendly web applications with just a few lines of code. It is very easy to use and requires absolutely no knowledge of HTML, CSS, or JavaScript.\n",
    "\n",
    "---\n",
    "\n",
    "We should have Streamlit already installed in our environment. You probably should take a look at the [Streamlit documentation](https://docs.streamlit.io/library), but this is how you can run a simple Streamlit app:\n",
    "\n",
    "Take look at `data/streamlit/app.py`. It is a tiny Streamlit app that takes a name as input and **returns a random fortune cookie-like quote**. Analyze the code and try to understand how it works. \n",
    "\n",
    "**Some important functions you may need to use:**\n",
    "\n",
    "- `st.title` sets the title of the app\n",
    "- `st.write` writes text to the app (supports [Markdown](https://www.markdownguide.org/basic-syntax/) synthax for text formatting)\n",
    "- `st.dataframe` displays a dataframe\n",
    "- `st.latex` renders LaTeX code (for mathematical formulas)\n",
    "- `st.text_input` creates a text input field (for multiline inputs, use `st.text_area`)\n",
    "- `st.button` creates a button (you can use it to trigger some action)\n",
    "\n",
    "To run the app, open a terminal and run the following command:\n",
    "\n",
    "    streamlit run data/streamlit/app.py\n",
    "    \n",
    "This will start a local server and open a new tab in your browser with the app. You can now interact with the app by entering your name and clicking the button to get a random fortune."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f89948b93e1fa0",
   "metadata": {},
   "source": [
    "## Exercise 5: Build an app for solubility prediction (3 points)\n",
    "\n",
    "This exercise is a continuation of the previous one. We will use all the code we have written so far to build a simple web app that predicts the solubility of molecules. The app will run in the browser and allow the user to input one or more SMILES strings, and it will display the predicted solubility of the molecules.\n",
    "The [Streamlit documentation](https://docs.streamlit.io/library) will be very helpful in this task.\n",
    "\n",
    "**The app should have the following structure:**\n",
    "\n",
    "1. A title and a short description of what the app does.\n",
    "2. A text area where the user can input a SMILES string (or multiple SMILES strings in a column).\n",
    "3. A button to submit the input.\n",
    "4. A section that displays the predicted solubility of the molecule(s) as a table of SMILES strings and their corresponding solubility values.\n",
    "\n",
    "The app should use our `Featurizer` class to extract the features from the input SMILES strings and predict the solubility using the trained model. **The model and the featurizer should not be trained inside the app, but loaded from a `.pkl` file instead!** Thanks to this approach, we will not need the training data to run the app. Both the model and the featurizer are already trained and saved as Python objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500173bbd37dfa41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this exercise, you should create a new Python script called in the 'data/streamlit' directory and implement the app there."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
